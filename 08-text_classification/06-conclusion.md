# 정리

이번 챕터에서는 텍스트 분류에 대해서 다루었습니다. 텍스트 분류는 비록 모델 구조의 복잡도나 코드 작성의 난이도에 비해서 매우 활용도가 높은 분야 입니다. 하지만 높은 활용도와 필요성에도 불구하고 기존 뉴럴 네트워크를 사용하기 이전에는 대부분 여전히 discrete한 값을 희소성(sparsity)문제를 해결하지 못한 채 나이브 베이즈(Naive Bayes)와 같은 방법을 통해 텍스트 또는 문장을 분류하곤 하였습니다. 나이브 베이즈도 매우 간단하고 직관적이며 의외로 높은 성능을 보여줄때도 있지만, 나이브 베이즈에 사용된 강력한 가정(각 피쳐는 독립)으로 인해서 분류의 정확도가 떨어질 수 밖에 없었습니다.

하지만 우리는 이제 뉴럴 네트워크를 통해서 매우 효율적이고 정확하게 문장 분류를 수행할 수 있습니다. RNN을 통해서 단어들을 순차적으로 받아 가장 마지막 time-step에서 분류를 예측하기도 하고, CNN을 통해서 분류에 중효한 단어들의 조합에 대한 패턴을 감지하기도 하였습니다. 여기에서 알 수 있듯이, RNN은 대체로 문장 전체의 맥락과 의미에 좀 더 집중하여 분류를 수행하며, CNN의 경우에는 해당 클래스를 나타내는 단어 조합에 대한 패턴의 유무가 가장 중요하게 여겨집니다. 따라서 두 방법을 서로 보완하기 위하여, 조합하여 앙상블 모델로 구현한다면 훨씬 더 좋은 결과를 얻을 수도 있습니다. <comment> 이는 저자의 깃허브에서 제공되는 소스코드에 구현되어 있습니다. </comment> 또한, RNN과 CNN을 활용하는 이 분류 모델들은 가장 간단한 구조들이므로, 이를 기반으로 발전한 다른 모델들을 참고한다면 긴 문장이나 어려운 텍스트에 대해서도 더 높은 성능을 얻을 수 있을 것 입니다. 다만 뉴럴 네트워크를 사용하는 방법이니 만큼, 데이터가 매우 적은 상황에서는 한계가 있다는 점을 명심해야 할 것 입니다.
