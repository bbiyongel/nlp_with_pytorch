# 흔한 오해 2

종종 텍스트 분류를 위해서 전처리 후 문장 내 접사 등의 토큰을 없애서, 표제어 추출(lemmatization) 또는 어간 추출(stemming)을 한 이후에 텍스트 분류를 해야 하는 것인지에 대한 질문을 받습니다. 이는 텍스트 분류 문제를 해결할 때 흔히 하는 오해 중 하나 입니다. 여기서 표제어 또는 어간 추출을 하게 되면 아래와 같은 형태의 문장이 됩니다.

|단계|문장|
|-|-|
|원문|나는 학교에 가요.|
|전처리|나 는 학교 에 가 요 .|
|추출|나 학교 가 .|

따라서 원문에 비교하면 훨씬 더 희소성에서 이득을 볼 수 있을 것 같습니다. 표제어 또는 어간 추출 모듈의 정책에 따라 다르겠지만, "나 학교 가 ."와 같은 추출 결과를 얻을 수 있는 원문의 종류는 굉장히 많을 것이기 때문 입니다.

|번호|문장|
|-|-|
|1|나는 학교에 가요.|
|2|나도 학교로 가요.|
|3|나는 학교를 가요.|
|4|나만 학교에 가요.|
|5|나도 학교를 가요.|
||...|

따라서 코퍼스가 부족한 상황에서는 위와 같이 어간이나 표제어가 같은 문장에 대해서는 같은 샘플로 취급하여 희소성 문제를 어느정도 타협할 수 있을 것 입니다. 특히, 딥러닝 이전의 전통적인 머신러닝 방법에서는 단어 및 문장은 여전히 discrete한 존재이므로 희소성 문제에 있어서 치명적인 단점이 있었기 때문에, 표제어 추출 및 어간 추출 방법은 종종 좋은 돌파구를 마련해 줄 수 있었습니다.

하지만 딥러닝의 시대에 접어들면서, 성공적으로 차원축소(dimension reduction)<comment> 단어 임베딩 챕터 참고 바랍니다. </comment>를 수행할 수 있게 됨으로써, 희소성으로 인해 야기된 문제는 더이상 큰 장애물이 되지 않습니다. 따라서 표제어 추출 및 어간 추출이 정석이라고 볼 수는 없을 것 입니다.

예를 들어, 아래와 같은 문장에 대해서 감성분석을 수행한다면, 표제어 추출 또는 어간 추출을 한 경우에는 어려울 것 입니다.

|원문|추출 후|정답|
|-|-|-|
|나는 학교에 가요.|나 학교 가 .|긍정 또는 중립|
|나만 학교에 가요.|나 학교 가 .|부정|

따라서 처음부터 표제어 추출 또는 어간 추출을 한 이후에 텍스트 분류 문제에 접근하는 것보다는, 일단은 표제어 또는 어간 추출을 하지 않은 상태에서, 이후 설명할 뉴럴 네트워크 모델들을 사용하여 텍스트 분류 문제 해결을 시도하여 베이스라인(baseline) 성능을 확보함이 바람직합니다. 이후에 성능 향상을 위한 차원에서 여러가지 튜닝 및 시도를 할 때에 코퍼스의 양이 부족한 것이 성능 저하의 원인이라는 가정이 있을 때, 표제어 및 어간 추출 등을 추가적으로 실험해 보는 것이 낫습니다.
