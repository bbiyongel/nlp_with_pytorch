# References

1. [[Abdel-Hamid et al.,2014](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CNN_ASLPTrans2-14.pdf)] Convolutional Neural Networks for Speech Recognition
1. [[Bahdanau et al.,2014](https://arxiv.org/abs/1409.0473)] Neural Machine Translation by Jointly Learning to Align and Translate
1. [[Bahdanau et al.,2016](https://arxiv.org/abs/1409.0473)] Neural Machine Translation by Jointly Learning to Align and Translate
1. [[Bojanowski et al.,2016](https://arxiv.org/abs/1607.04606)] Enriching Word Vectors with Subword Information
1. [[Chambers et al.,2010](https://web.stanford.edu/~jurafsky/chambers-acl2010-pseudowords.pdf)] Improving the Use of Pseudo-Words for Evaluating Selectional Preferences
1. [[Chiu et al.,2017](https://arxiv.org/abs/1712.01769)] State-of-the-art Speech Recognition With Sequence-to-Sequence Models
1. [[Church et al.,1991](https://www.sciencedirect.com/science/article/pii/088523089190016J)] A comparison of the enhanced Good-Turing and deleted estimation methods for estimating probabilities of English bigrams
1. [[Conneau et al.,2017](https://arxiv.org/abs/1710.04087)] WORD TRANSLATION WITHOUT PARALLEL DATA
1. [[Currey et al.,2017](https://kheafield.com/papers/edinburgh/copy_paper.pdf)] Copied Monolingual Data Improves Low-Resource Neural Machine Translation
1. [[Devlin et al.,2018](https://arxiv.org/abs/1810.04805)] BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
1. [[Erk et al.,2007](http://www.aclweb.org/anthology/P07-1028)] A Simple, Similarity-based Model for Selectional Preferences
1. [[Gao et al.,2017](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/dl-summer-school-2017.-Jianfeng-Gao.v2.pdf)] An Introduction to Deep Learning for Natural Language Processing
1. [[Gehring et al.,2017](https://arxiv.org/abs/1705.03122)] Convolutional Sequence to Sequence Learning
1. [[Goodfellow et al.,2014](https://arxiv.org/abs/1406.2661)] Generative Adversarial Networks
1. [[Graves et al.,2016](https://www.gwern.net/docs/2016-graves.pdf)] Hybrid computing using a neural network with dynamic external memory
1. [[Gulcehre et al.,2015](https://arxiv.org/abs/1503.03535)] On Using Monolingual Corpora in Neural Machine Translation
1. [[Hassan et al.,,2018](https://arxiv.org/abs/1803.05567)] Achieving Human Parity on Automatic Chinese to English News Translation
1. [[He et al.,2015](https://arxiv.org/abs/1512.03385)] Deep Residual Learning for Image Recognition
1. [[He et al.,2016a](https://arxiv.org/abs/1611.00179)] Dual Learning for Machine Translation
1. [[Joulin et al.,2016](https://arxiv.org/abs/1607.01759)] Bag of Tricks for Efficient Text Classification
1. [[Karras et al.,2017](https://arxiv.org/abs/1710.10196)] Progressive Growing of GANs for Improved Quality, Stability, and Variation
1. [[Karras et al.,2018](https://arxiv.org/abs/1812.04948)] A Style-Based Generator Architecture for Generative Adversarial Networks
1. [[Kim, 2014](https://arxiv.org/abs/1408.5882)] Convolutional Neural Networks for Sentence Classification
1. [[Kingma et al.,2013](https://arxiv.org/abs/1312.6114)] Auto-Encoding Variational Bayes
1. [[Kingma et al.,2014](https://arxiv.org/abs/1412.6980)] Adam: A Method for Stochastic Optimization
1. [[Kneser et al.,1995](https://www.semanticscholar.org/paper/Improved-backing-off-for-M-gram-language-modeling-Kneser-Ney/9548ac30c113562a51e603dbbc8e9fa651cfd3ab)] Improved backing-off for M-gram language modeling
1. [[Liu et al.,2016](https://arxiv.org/abs/1606.07536)] Coupled Generative Adversarial Networks
1. [[Loung et al.,2015](https://arxiv.org/abs/1508.04025)] Effective Approaches to Attention-based Neural Machine Translation
1. [[Mikolov et al.,2010](https://www.isca-speech.org/archive/archive_papers/interspeech_2010/i10_1045.pdf)] Recurrent neural network based language model
1. [[Mikolov et al.,2013](https://arxiv.org/pdf/1310.4546)] Distributed Representations of Words and Phrases and their Compositionality
1. [[Pennington et al.,2014](https://www.aclweb.org/anthology/D14-1162)] GloVe: Global Vectors for Word Representation
1. [[Radford et al.,2015](https://arxiv.org/abs/1511.06434)] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks
1. [[Resnik et al.,1997](http://www.aclweb.org/anthology/W97-0209)] Selectional Preference and Sense Disambiguation
1. [[Sennrich et al.,2015](https://arxiv.org/abs/1511.06709)] Improving Neural Machine Translation Models with Monolingual Data
1. [[Sennrich et al.,2016](https://arxiv.org/abs/1511.06709)] Improving Neural Machine Translation Models with Monolingual Data
1. [[Sennrich et al.,2017](https://arxiv.org/abs/1708.00726)] The University of Edinburgh's Neural MT Systems for WMT17
1. [[Shen et al.,2016](http://www.aclweb.org/anthology/P16-1159)] Minimum Risk Training for Neural Machine Translation
1. [[Sundermeyer at el.2012](https://www.isca-speech.org/archive/archive_papers/interspeech_2012/i12_0194.pdf)] LSTM Neural Networks for Language Modeling
1. [[Sutskever et al.,2014](https://arxiv.org/abs/1409.3215)] Sequence to Sequence Learning with Neural Networks
1. [[Sutton at el.1999](https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf)] Policy Gradient Methods for Reinforcement Learning with Function Approximation
1. [[Vaswani at el.2017](https://arxiv.org/abs/1706.03762)] Attention Is All You Need
1. [[Wang et al.,2017](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/11/17041-72820-1-SM.pdf)] Dual Transfer Learning for Neural Machine Translation with Marginal Distribution Regularization
1. [[Xia et al.,2017a](https://arxiv.org/abs/1707.00415)] Dual Supervised Learning (DSL)
1. [[Xia et al.,2017b](https://papers.nips.cc/paper/6775-deliberation-networks-sequence-generation-beyond-one-pass-decoding.pdf)] Deliberation Networks
1. [[Yu et al.,2016](https://arxiv.org/abs/1609.05473)] SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient
1. [[Zhang et al.,2018](https://arxiv.org/abs/1803.00353)] Joint Training for Neural Machine Translation Models with Monolingual Data
