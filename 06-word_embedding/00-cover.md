# Word Embedding Vector

![Tomas Mikolov: Research Scientist at Facebook](../assets/06-00-01.jpg){ width=500px }

딥러닝은 여러 레이어(layer)와 비선형 활성함수(non-linear activation function)들을 거치면서 필요한 특징 정보를 추출합니다. 이 과정에서 정보를 압축시켜, 정보의 불필요한 부분은 버리고 필요한 부분만 수집하여 이를 정답 결과값과 같아지도록 학습 합니다. 사람의 언어는 매우 방대하고 불연속적인 데이터이므로 굉장히 비효율적으로 아주 높은 차원의 공간에 희소(sparse)하게 퍼져 있습니다. 따라서 이러한 자연어처리의 어려움을 해결하기 위한 딥러닝을 통한 압축 과정과 정보 추출이 매우 중요합니다. 결과적으로 이는 기존의 자연어처리 방식에 비해서 훨씬 뛰어난 성능이 나오는 결과를 만들어 냈습니다. 마찬가지로 우리는 뉴럴 네트워크를 통해 기존의 특징 벡터 표현 방식보다 훨씬 더 정확한 특징 벡터 표현 방법을 학습 할 수 있습니다. 이번 챕터에서는 가장 대표적인 Word2Vec에 대해 소개하고, Word2Vec의 단점을 보완한 GloVe를 이야기 하고자 합니다. 따라서 이에 앞서 딥러닝의 동작 원리에 대한 이해를 도울 수 있도록, 딥러닝의 비선형 차원축소에 대해서 이야기 하는 시간도 갖도록 합니다.
