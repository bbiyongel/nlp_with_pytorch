Found 102 files.
./14-productization/03-nematus.md	![BPE 알고리즘 - 출처: [[Sennrich at el.2016]](http://www.aclweb.org/anthology/P16-1162)](../assets/nmt-edinburgh-1.png){ width=400px }
./14-productization/04-microsoft.md	![](../assets/nmt-productization-msnmt-joint-training.png)
./14-productization/04-microsoft.md	![딜리버레이션 네트워크의 개요](../assets/nmt-productization-msnmt-deliberation.png)
./14-productization/04-microsoft.md	![](../assets/nmt-productization-msnmt-deliberation-implementation.png)
./14-productization/04-microsoft.md	![](../assets/nmt-productization-msnmt-kld.png)
./14-productization/04-microsoft.md	![](../assets/nmt-productization-msnmt-evaluation.png)
./14-productization/01-pipeline.md	![준비과정 개요도](../assets/image_needed.jpeg)
./14-productization/02-gnmt.md	![레지듀얼 커넥션을 적용한 모습](../assets/nmt-gnmt-1.png)
./14-productization/02-gnmt.md	![인코더의 첫번째 레이어에 적용 된 모습](../assets/nmt-gnmt-2.png)
./14-productization/02-gnmt.md	![](../assets/nmt-gnmt-5.png)
./14-productization/02-gnmt.md	![양자화에 따른 성능 개선 효과 - 출처: [Wo at el.2016]](../assets/nmt-gnmt-3.png)
./14-productization/02-gnmt.md	![Optimizer에 따른 손실값의 변화](../assets/nmt-gnmt-4.png)
./14-productization/02-gnmt.md	![](../assets/nmt-gnmt-6.png)
./14-productization/00-cover.md	![적절한 번역의 예](../assets/nmt-waldo.png){ width=500px }
./12-reinforcement_learning/01-intro.md	![GAN의 전형적인 구조](https://sthalles.github.io/assets/dcgan/GANs.png)
./12-reinforcement_learning/01-intro.md	![L1 손실함수와 GAN의 생성 결과물 비교 (출처: pix2pix)](../assets/rl-mse_vs_gan.png)
./12-reinforcement_learning/01-intro.md	![GAN을 sequence-to-sequence에 적용하자](../assets/rl-seq2seq_gan.png)
./12-reinforcement_learning/01-intro.md	![샘플링 과정은 그래디언트 전달이 어렵습니다.](../assets/rl-stochastic_cannot_back_prop.png)
./12-reinforcement_learning/05-supervised-nmt.md	![MRT의 성능 평가](../assets/rl-minimum-risk-training.png)
./12-reinforcement_learning/04-characteristic.md	![강화학습을 기계번역에 적용한다면](../assets/rl-rl_to_nmt.png)
./12-reinforcement_learning/02-rl_basics.md	![강화학습이 동작하는 과정](../assets/rl-universe.png)
./12-reinforcement_learning/02-rl_basics.md	![가위바위보](../assets/rl-rpc.png)
./12-reinforcement_learning/02-rl_basics.md	![가장 어려운 고민](../assets/rl-policy-choice.png)
./12-reinforcement_learning/02-rl_basics.md	![백트래킹과 다이나믹 프로그래밍](../assets/rl-exhaustive_search_vs_dp.png)
./12-reinforcement_learning/02-rl_basics.md	![](../assets/rl-policy_iteration.png)
./12-reinforcement_learning/02-rl_basics.md	![뉴럴 네트워크를 활용한 큐 러닝의 개요](../assets/rl-atari.png)
./12-reinforcement_learning/03-policy-gradient.md	![손실 함수를 최소화 하기 위한 그래디언트 디센트 vs 샘플링을 통한 보상의 최대화를 위한 그래디언트 어센트](../assets/rl_sgd_vs_policy_gradients.png)
./12-reinforcement_learning/03-policy-gradient.md	![폴리시 그래디언트는 샘플링 확률을 최대화 하는 방향으로 그래디언트를 구합니다.](../assets/rl-policy_gradient_ascent.png)
./12-reinforcement_learning/06-unsupervised-nmt.md	![Unsupervised NMT 개요](../assets/rl-unsupervised-nmt-3.png)
./12-reinforcement_learning/06-unsupervised-nmt.md	![3가지 목적함수가 동작하는 모습](../assets/rl-unsupervised-nmt-4.png)
./12-reinforcement_learning/06-unsupervised-nmt.md	![](../assets/rl-unsupervised-nmt-5.png)
./12-reinforcement_learning/00-cover.md	![Richard S. Sutton 교수](https://cdn-images-1.medium.com/max/1200/1*aIslMzbp8-olmVVQHyxBbg.jpeg){ width=500px }
./11-adv_neural_machine_translation/01-multilingual-nmt.md	![Many to One](../assets/nmt-zeroshot-1.png)
./11-adv_neural_machine_translation/01-multilingual-nmt.md	![One to Many](../assets/nmt-zeroshot-2.png)
./11-adv_neural_machine_translation/01-multilingual-nmt.md	![Many to Many](../assets/nmt-zeroshot-3.png)
./11-adv_neural_machine_translation/01-multilingual-nmt.md	![Zero-shot Translation](../assets/nmt-zeroshot-4.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![[[Gulcehre at el.2015]](https://arxiv.org/pdf/1503.03535.pdf)](../assets/nmt_with_lm_ensemble.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![[[Gulcehre at el.2015]](https://arxiv.org/pdf/1503.03535.pdf)](../assets/nmt_with_lm_ensemble_evaluation.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![Back Translation 개요](../assets/nmt_back_translation_overview.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![[[Sennrich at el.2015]](https://arxiv.org/pdf/1511.06709.pdf)](../assets/nmt_back_translation.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![[[Sennrich at el.2017]](https://arxiv.org/pdf/1708.00726.pdf)](../assets/nmt_copied_translation.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![](../assets/rl-unsupervised-nmt-1.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![](../assets/rl-unsupervised-nmt-2.png)
./11-adv_neural_machine_translation/03-transformer.md	![트랜스포머의 구조](../assets/nmt-transformer-1.png)
./11-adv_neural_machine_translation/03-transformer.md	![포지션 임베딩의 직관적인 설명](../assets/image_needed.jpeg)
./11-adv_neural_machine_translation/03-transformer.md	![트랜스포머의 어텐션 구성](../assets/nmt-transformer-2.png)
./11-adv_neural_machine_translation/03-transformer.md	![트랜스포머는 모든 time-step의 어텐션 연산을 한 번에 수행합니다.](../assets/adv_nmt-attention_bmm.png)
./11-adv_neural_machine_translation/03-transformer.md	![트랜스포머의 성능 비교](../assets/nmt-transformer-3.png)
./11-adv_neural_machine_translation/00-cover.md	![[Christopher Manning](https://nlp.stanford.edu/manning/)](../assets/cover-manning.jpeg){ width=500px }
./08-text_classification/05-cnn.md	![CNN for text classification arthictecture [[Kim at el.2014]](https://arxiv.org/pdf/1408.5882.pdf)](../assets/tc-cnn-text-classification.png)
./08-text_classification/05-cnn.md	![수직, 수평 윤곽선을 검출하기 위한 소벨(Sobel)필터](../assets/tc-cnn-sobel-filter.gif)
./08-text_classification/05-cnn.md	![소벨 필터 적용 전 (출처: 위키피디아)](https://upload.wikimedia.org/wikipedia/commons/f/f0/Valve_original_%281%29.PNG)
./08-text_classification/05-cnn.md	![소벨 필터 적용 후 (출처: 위키피디아)](https://upload.wikimedia.org/wikipedia/commons/d/d4/Valve_sobel_%283%29.PNG)
./08-text_classification/05-cnn.md	![컨볼루션 연산을 적용하는 과정](../assets/tc-convolution.png)
./08-text_classification/05-cnn.md	![Example of convolutional neural network for speech recognition [ Abdel-Hamid et al.2014](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CNN_ASLPTrans2-14.pdf)](../assets/tc-audio-cnn.png)
./08-text_classification/05-cnn.md	![두 단어(토큰)의 패턴을 찾는 CNN](../assets/tc-cnn-architecture.png)
./08-text_classification/05-cnn.md	![cnn_out에서 맥스 풀링을 통해 각 피쳐 별 최고 점수를 뽑아내는 과정](../assets/tc-max_pooling.png)
./08-text_classification/04-rnn.md	![RNN의 마지막 time-step의 출력을 사용 하는 경우](../assets/rnn-apply-1.png)
./08-text_classification/04-rnn.md	![One-hot 벡터로 구성된 정답 샘플과 뉴럴 네트워크를 통해 얻은 discrete 확률 분포 사이의 손실 함수 계산](../assets/tc-cross_entropy.png)
./08-text_classification/00-cover.md	![[Thomas Bayes](https://en.wikipedia.org/wiki/Thomas_Bayes) - Image from Wikipedia](https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif)
./04-preprocessing/01-intro.md	![전처리 과정 개요도](../assets/image_needed.jpeg)
./04-preprocessing/05-align.md	![Jean-François Champollion, 이미지 출처: 위키피디아](https://upload.wikimedia.org/wikipedia/commons/f/ff/Jean-Francois_Champollion.jpg)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/preproc-regex-oneof.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/preproc-regex-dash.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/preproc-regex-none_of.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/preproc-regex-group.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/preproc-regex-or.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/preproc-regex-question.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/preproc-regex-plus.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/preproc-regex-star.png)
./04-preprocessing/03-cleaning-corpus.md	![n번 반복](../assets/preproc-regex-n.png)
./04-preprocessing/03-cleaning-corpus.md	![n번 이상 반복](../assets/preproc-regex-n_comma.png)
./04-preprocessing/03-cleaning-corpus.md	![n번에서 m번 사이 반복](../assets/preproc-regex-n_to_m.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/preproc-regex-dot.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/preproc-regex-start_end.png)
./04-preprocessing/03-cleaning-corpus.md	![이미지 출처: [regexper.com](https://regexper.com/)](../assets/preproc-regex-phone_number.png)
./04-preprocessing/03-cleaning-corpus.md	![치환자 사용의 예](../assets/preproc-regex-substitution.png)
./04-preprocessing/00-cover.md	![Noam Chomsky](https://upload.wikimedia.org/wikipedia/commons/a/a9/Noam_Chomsky_portrait_2017.jpg){ width=400px }
./02-basic_math/02-prob-dist.md	![주사위의 확률 질량 함수(probability mass function)](../assets/basic_math-pmf.png)
./02-basic_math/02-prob-dist.md	![가우시안 분포의 확률 밀도 함수(probability density funcion)](../assets/basic_math-pdf.png)
./02-basic_math/02-prob-dist.md	![Marginal 확률 분포의 개념](../assets/basic_math-marginal.png)
./02-basic_math/05-mle.md	![어느 평범한 압정](../assets/basic_math-push_pin.png)
./02-basic_math/05-mle.md	![Likelihood 함수 곡선](../assets/basic_math-binomial.png)
./02-basic_math/05-mle.md	![뉴럴 네트워크는 확률분포 함수 입니다.](../assets/basic_math-nn_is_prob_dist.png)
./02-basic_math/06-information.md	![flat한 분포와 sharp한 분포](../assets/basic_math-flat_and_sharp.png)
./02-basic_math/06-information.md	![크로스 엔트로피의 직관적인 표현](../assets/basic_math-cross_entropy_intuition.png)
./02-basic_math/04-sampling.md	![주사위](../assets/lm_rolling_dice.png)
./02-basic_math/04-sampling.md	![한반도의 넓이를 근사하고 싶다면?](../assets/basic_math-korea.png)
./02-basic_math/03-monty-hall.md	![몬티홀 문제](../assets/appendix-monty_hall.png)
./02-basic_math/00-cover.md	![Claude Elwood Shannon - 이미지 출처: 위키피디아](https://upload.wikimedia.org/wikipedia/commons/9/99/ClaudeShannon_MFO3807.jpg){ width=500px }
./05-word_senses/01-intro.md	![단어의 형태들과 내부 의미들이 갖는 관계](../assets/wsd-word_sense_meaning.png)
./05-word_senses/07-similarity.md	![L1 vs L2(초록색) from wikipedia](https://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Manhattan_distance.svg/283px-Manhattan_distance.svg.png)
./05-word_senses/07-similarity.md	![같은 값 $r$ 크기를 갖는 $L_1$ , $L_2$ , $L_\infty$ 거리를 그림으로 나타낸 모습](../assets/wsd-distance.png)
./05-word_senses/04-feature.md	![각 피쳐에 따른 MNIST 예제](../assets/wsd-mnist_feature.png)
./05-word_senses/09-selectional-preference.md	![클래스의 사전 확률 분포와 술어가 주어졌을 때의 확률 분포 변화](../assets/wsd-selectional-preference-strength.png)
./05-word_senses/09-selectional-preference.md	![](../assets/wsd-banana_door.png)
./05-word_senses/02-one-hot-encoding.md	![Discrete 확률 분포로부터 샘플링하여 얻어지는 One-hot 벡터](../assets/wsd-one_hot_from_discrete_prob_dist.png)
./05-word_senses/02-one-hot-encoding.md	![차원의 저주: 차원이 높을 수록 같은 정보를 표현하는데 불리합니다.](../assets/wsd-curse_of_dimensionality.png)
./05-word_senses/03-wordnet.md	![각 단어별 top-1 의미의 top-1 상위어만 선택하여 트리 구조로 나타낸 경우](../assets/wsd-wordnet_hierarchy.png)
./05-word_senses/03-wordnet.md	![[워드넷 웹사이트](http://wordnetweb.princeton.edu/perl/webwn)에서 단어 'bank'를 검색 한 결과](../assets/wsd-wordnet_screenshot.png)
./05-word_senses/03-wordnet.md	![각 단어들의 쿼리 결과 구조도](../assets/wsd-wordnet_hierarchy.png)
./05-word_senses/03-wordnet.md	!['student'와 'fireman' 사이에 위치한 노드들(점선)](../assets/wsd-wordnet_distance.png)
./05-word_senses/06-vectorization.md	![컨텍스트 윈도우를 수행한 결과](../assets/wsd-context-window.png)
./05-word_senses/06-vectorization.md	![대부분의 값이 0으로 채워진 sparse 벡터](../assets/wsd-sparse-vector.png)
./05-word_senses/06-vectorization.md	![피쳐 벡터들을 tSNE로 표현한 모습](../assets/wsd-feature-vector-tsne.png)
./05-word_senses/00-cover.md	![Philip Resnik](https://legacydirs.umiacs.umd.edu/~resnik/photos/headshots/umiacs/20111116_PhilipResnik30_web.jpg){ width=500px }
./07-sequential_modeling/03-lstm.md	![LSTM의 구조](../assets/rnn-lstm-architecture.png)
./07-sequential_modeling/05-gradient-clipping.md	![그래디언트의 방향은 유지한 채, 크기만 달라지는 모습](../assets/rnn-gradient_clipping.png)
./07-sequential_modeling/02-rnn.md	![기존 뉴럴 네트워크 구조](../assets/rnn-fc.png)
./07-sequential_modeling/02-rnn.md	![Recursive한 속성이 부여된 뉴럴넷 구조](../assets/rnn-basic.png)
./07-sequential_modeling/02-rnn.md	![기본적인 RNN의 피드포워드 형태](../assets/rnn-basic-architecture.png)
./07-sequential_modeling/02-rnn.md	![RNN의 입력 텐서 (n time-step)](../assets/rnn-input_tensor.png)
./07-sequential_modeling/02-rnn.md	![여러 time-step의 히든스테이트들을 이어붙여 전체 time-step에 대한 히든스테이트로 만드는 모습](../assets/rnn-n_hidden_states.png)
./07-sequential_modeling/02-rnn.md	![RNN에서 BPTT가 되는 모습](../assets/rnn-back-prop.png)
./07-sequential_modeling/02-rnn.md	![빨간색: tanh, 파란색: sigmoid](../assets/rnn-tanh_sigmoid.png)
./07-sequential_modeling/02-rnn.md	![빨간색: tanh의 도함수, 파란색: sigmoid의 도함수](../assets/rnn-tanh_sigmoid_gradient.png)
./07-sequential_modeling/02-rnn.md	![여러 층이 쌓인 RNN의 형태](../assets/rnn-multi-layer.png)
./07-sequential_modeling/02-rnn.md	![RNN의 출력 텐서 (n time-step)](../assets/rnn-hidden_state_tensor.png)
./07-sequential_modeling/02-rnn.md	![여러개의 레이어를 가진 RNN의 히든스테이트 (1 time-step)](../assets/rnn-multi_layer_hidden_states.png)
./07-sequential_modeling/02-rnn.md	![두 방향으로 히든 스테이트를 전달 및 계산하는 RNN의 형태](../assets/rnn-bidirectional.png)
./07-sequential_modeling/02-rnn.md	![여러개의 레이어를 가진 양방향 RNN의 히든스테이트 (1 time-step)](../assets/rnn-multi_layer_bidirectional_hidden_states.png)
./07-sequential_modeling/02-rnn.md	![각 타입 별 RNN의 형태](../assets/rnn-type_by_type.png)
./07-sequential_modeling/02-rnn.md	![RNN의 마지막 time-step의 출력을 사용 하는 경우](../assets/rnn-apply-1.png)
./07-sequential_modeling/02-rnn.md	![모든 time-step의 출력을 사용 하는 경우](../assets/rnn-apply-2.png)
./07-sequential_modeling/04-gru.md	![GRU의 구조](../assets/rnn-gru-architecture.png)
./07-sequential_modeling/00-cover.md	![Andrey Markov](https://upload.wikimedia.org/wikipedia/commons/7/70/AAMarkov.jpg){ width=500px }
./01-introduction/01-intro.md	![텍스트는 사람과 컴퓨터 사이의 가장 훌륭한 인터페이스 입니다.](../assets/intro-text_is_interface.png)
./01-introduction/04-korean-is-hell.md	![내동생 고기 vs 내동 생고기](../assets/intro-why-korean-hell-my-bro.png)
./01-introduction/04-korean-is-hell.md	![농협용 인육 가공 vs 농협 용인 육가공](../assets/intro-why-korean-hell-human-meat.png)
./01-introduction/02-deeplearning.md	![이미지넷의 최근 성능 변화](../assets/intro-imagenet.png)
./01-introduction/02-deeplearning.md	![전통적인 음성인식 시스템의 구성](https://www.esat.kuleuven.be/psi/spraak/demo/Recog/lvr_scheme.gif)
./01-introduction/02-deeplearning.md	![음성인식의 정확도](../assets/intro-asr-accuracy.png)
./01-introduction/02-deeplearning.md	![2014년까지 참 안타까웠습니다.](../assets/intro-pepe.png)
./01-introduction/02-deeplearning.md	![통계기반 기게번역 시스템을 구성하는 서브 모듈 (SMT)](../assets/intro-smt.jpg)
./01-introduction/02-deeplearning.md	![기계번역의 역사](http://iconictranslation.com/wp-content/uploads/2017/06/NMT-Graph-2-a.png)
./01-introduction/02-deeplearning.md	![2014년부터 2018년까지 GAN의 역사를 한장에](../assets/intro-face-generation.png)
./01-introduction/02-deeplearning.md	![[[Gao et al.2017](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/dl-summer-school-2017.-Jianfeng-Gao.v2.pdf)]](../assets/intro-traditional-nlp.png)
./01-introduction/02-deeplearning.md	![[[Gao et al.2017](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/dl-summer-school-2017.-Jianfeng-Gao.v2.pdf)]](../assets/intro-paradigm-shift.png)
./01-introduction/02-deeplearning.md	![[[Gao et al.2017](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/dl-summer-school-2017.-Jianfeng-Gao.v2.pdf)]](../assets/intro-nlp-symbolic-vs-neural.png)
./01-introduction/02-deeplearning.md	![[[Gao et al.2017](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/dl-summer-school-2017.-Jianfeng-Gao.v2.pdf)]](../assets/intro-end-2-end-nlp-deep-learning.png)
./01-introduction/02-deeplearning.md	![아카이브에 출판된 딥러닝 관련 논문 수 - 출처: [Karpathy's medium](https://medium.com/@karpathy/a-peek-at-trends-in-machine-learning-ab8a1085a106)](../assets/intro-growth-of-deeplearning.png)
./01-introduction/05-trends.md	![[Mikolov et al.2010]](../assets/intro-rnnlm.png)
./01-introduction/05-trends.md	![Skip-gram과 CBOW의 구조 [Mikolov et al.2013]](../assets/intro-word2vec.png)
./01-introduction/05-trends.md	![Word Vector Visualization](../assets/intro-word-embedding.png)
./01-introduction/05-trends.md	![CNN 텍스트 분로 모델 [Kim et al.2014]](../assets/intro-cnn-text-classification.png)
./01-introduction/05-trends.md	![어텐션을 통해 두 문장 사이의 단어간 정렬이 된 모습](../assets/intro-word-alignment.png)
./01-introduction/05-trends.md	![[Graves et al.2016]](../assets/intro-dnc.png)
./01-introduction/05-trends.md	![[[Yu et al.2016]](https://arxiv.org/abs/1609.05473)](../assets/intro-seqgan.png)
./01-introduction/00-cover.md	![TARS from Interstellar - Image from [web](https://www.wired.com/2014/11/interstellar-droids/)](https://assets.wired.com/photos/w_1200/wp-content/uploads/2014/10/robots6_g.jpg){ width=500px }
./10-neural_machine_translation/06-beam-search.md	![샘플링 또는 그리디 탐색을 통한 추론 과정](../assets/image_needed.jpeg)
./10-neural_machine_translation/06-beam-search.md	![하나의 문장을 번역 할 때, 빔 사이즈 k=3인 경우의 빔서치](../assets/nmt-single-sample-beam-search.png)
./10-neural_machine_translation/06-beam-search.md	![](../assets/nmt-beam-search-concept.png)
./10-neural_machine_translation/06-beam-search.md	![각 추론 방법에 따른 성능 비교 - 출처: [Cho et al.2016]](../assets/nmt-inference-method-evaluation.png)
./10-neural_machine_translation/06-beam-search.md	![빔 사이즈 k=3인 경우의 병렬 빔서치 수행](../assets/nmt-beam-search-space.png)
./10-neural_machine_translation/06-beam-search.md	![미니배치 내에서 빔서치를 병렬로 수행하기 위한 과정](../assets/nmt-mini-batch-parallelized-beam-search-overview.png)
./10-neural_machine_translation/01-intro.md	![대표적인 번역 실패 사례](../assets/nmt-no-evil.png)
./10-neural_machine_translation/01-intro.md	![[오토인코더 기반의 신경망 기계번역](http://web.stanford.edu/class/cs224n/syllabus.html)](../assets/nmt-autoencoder.png)
./10-neural_machine_translation/01-intro.md	![[통계기반 기계번역 vs 신경망 기계번역](http://web.stanford.edu/class/cs224n/syllabus.html)](../assets/nmt-progress-in-mt.png)
./10-neural_machine_translation/05-teacher-forcing.md	![훈련방식과 추론방식](../assets/image_needed.jpeg)
./10-neural_machine_translation/02-seq2seq.md	![3개의 구성요소로 이루어진 기본적인 Sequence-to-Sequence 구조](../assets/nmt-seq2seq-architecture.png)
./10-neural_machine_translation/02-seq2seq.md	![인코더의 문장 임베딩](../assets/nmt-enc-sent-proj.png)
./10-neural_machine_translation/03-attention.md	![어텐션이 추가된 Sequence-to-Sequence의 구조](../assets/nmt-seq2seq-with-attention-architecture.png)
./10-neural_machine_translation/03-attention.md	![인코더의 출력값과 디코더의 출력값 사이의 선형 맵핑](../assets/nmt-attention-linear-transform.png)
./10-neural_machine_translation/03-attention.md	![어텐션이 번역에서 동작하는 직관적인 예](../assets/nmt-attention-working-example.png)
./10-neural_machine_translation/03-attention.md	![[어텐션의 사용여부에 따른 문장 길이별 번역 성능](http://web.stanford.edu/class/cs224n/syllabus.html)](../assets/nmt-attention-evaluation-graph.png)
./10-neural_machine_translation/03-attention.md	![파이토치 배치 행렬곱 연산](../assets/nmt-bmm.png)
./10-neural_machine_translation/04-input-feeding.md	![Input Feeding이 추가 된 Sequence-to-Sequence 구조](../assets/nmt-seq2seq-with-attention-and-input-feeding-architecture.png)
./10-neural_machine_translation/04-input-feeding.md	![문장 길이에 따른 미니배치의 형태](../assets/nmt-variable_length_minibatch.png)
./10-neural_machine_translation/04-input-feeding.md	![마스크가 적용되었을 때 어텐션](../assets/nmt-masked_attention.png)
./10-neural_machine_translation/04-input-feeding.md	![Bi-directional LSTM의 히든 스테이트를 uni-directional LSTM의 히든 스테이트로 바꾸기](../assets/nmt-encoder-to-decoder.png)
./10-neural_machine_translation/00-cover.md	![[Kyunghyun Cho](http://www.kyunghyuncho.me/)](https://cims.nyu.edu/people/profiles/images/Cho_Kyunghyun.jpg)
./13-duality/01-intro.md	![듀얼리티의 예](../assets/image_needed.jpeg)
./13-duality/01-intro.md	![CycleGAN이 성공적으로 적용된 예제](https://junyanz.github.io/CycleGAN/images/teaser.jpg)
./13-duality/01-intro.md	![CycleGAN의 동작 개요](../assets/rl-cycle-gan.png)
./13-duality/04-back_translation.md	![젠슨스 부등식의 예](../assets/duality-jensens_inequality.png)
./13-duality/02-dsl.md	![](../assets/duality-dsl-eval.png)
./13-duality/03-dul.md	![기계번역 듀얼러닝의 알고리즘](../assets/rl-dual-learning-1.png)
./13-duality/03-dul.md	![](../assets/rl-dual-learning-2.png)
./13-duality/03-dul.md	![듀얼러닝의 적용 결과](../assets/rl-dual-learning-3.png)
./13-duality/03-dul.md	![](../assets/duality-dul-eval.png)
./13-duality/00-cover.md	![[Dr. Rico Sennrich](http://homepages.inf.ed.ac.uk/rsennric/)](https://homepages.inf.ed.ac.uk/rsennric/files/rico-klein2.jpg){ width=400px }
./03-pytorch_tutorial/02-how-to-install.md	![파이토치 홈페이지에서는 그림에서와 같이 사용자의 설정에 따른 설치 명령을 제공 합니다.](../assets/pytorch_intro-how_to_install.png)
./03-pytorch_tutorial/02-how-to-install.md	![PyTorch 로고](../assets/pytorch_intro-logo.png)
./03-pytorch_tutorial/02-how-to-install.md	![시간별 딥러닝 프레임워크의 점유율 변화 출처: [Karpathy's medium](https://medium.com/@karpathy/a-peek-at-trends-in-machine-learning-ab8a1085a106)](../assets/pytorch_intro-growth.png)
./03-pytorch_tutorial/02-how-to-install.md	![[Image from [Karpathy's twitter](https://twitter.com/karpathy/status/868178954032513024)](../assets/pytorch_intro-Karpathy.png)
./03-pytorch_tutorial/03-hello-pytorch.md	![연산에 의해 생성된 그래프의 예](../assets/pytorch_intro-computation_graph.png)
./03-pytorch_tutorial/00-cover.md	![Geoffrey Hinton](https://images.thestar.com/content/dam/thestar/news/world/2015/04/17/how-a-toronto-professors-research-revolutionized-artificial-intelligence/geoffrey-hinton-3.jpg){ width=500px }
./06-word_embedding/03-myth.md	![임베딩 레이어의 동작 개념](../assets/w2v-embedding-layer.png)
./06-word_embedding/04-word2vec.md	![CBOW와 Skip-gram 알고리즘](../assets/intro-word2vec.png)
./06-word_embedding/04-word2vec.md	![Skip-gram의 아키텍쳐](../assets/wsd-skip_gram_architecture.png)
./06-word_embedding/04-word2vec.md	![Skip-gram을 통해 얻은 word embedding 벡터를 t-SNE를 통해 visualization 한 예제](../assets/intro-word-embedding.png)
./06-word_embedding/06-example.md	![텐서보드를 통한 시각화 예제](https://2.bp.blogspot.com/-Uql7bl2KEYM/WEfQ4Kl_0YI/AAAAAAAABck/GkktuPM8KoMcMl2Tot6GzH3-NgwPNETMgCLcB/s640/image03.png)
./06-word_embedding/06-example.md	![텐서보드를 통한 시각화 예제](https://2.bp.blogspot.com/-yL_425HS2ck/WEDZLk5cq0I/AAAAAAAABcI/kwy4F4Cmfi4jyG_InIiYu6F7y2-BKTXWQCLcB/s640/embedding-mnist.gif)
./06-word_embedding/02-dimension-reduction.md	![심지어 One-hot 벡터의 경우에는 아래와 같이 차원 축소가 가능할 것 입니다.](../assets/w2v-one-hot-dimension-reduction.png)
./06-word_embedding/02-dimension-reduction.md	![3차원에서 2차원, 다시 1차원으로 PCA를 수행하는 예](../assets/w2v-pca-example.png)
./06-word_embedding/02-dimension-reduction.md	![주성분의 조건](../assets/w2v-pca-principles.png)
./06-word_embedding/02-dimension-reduction.md	![3차원 공간 상에 기묘한 모양으로 분포한 샘플들이 2차원 매니폴드에 속하는 모습](../assets/w2v-swiss-roll.png)
./06-word_embedding/02-dimension-reduction.md	![3차원 공간상의 2차원 매니폴드를 2차원 공간에서 표현하였을 때, 각 점 사이의 최단경로](../assets/w2v-manifold-distance.png)
./06-word_embedding/02-dimension-reduction.md	![MNIST 데이터를 2차원 매니폴드에 표현하였을 때, 두 샘플의 위치](../assets/w2v-manifold_distance_mnist_example.png)
./06-word_embedding/02-dimension-reduction.md	![3차원 데이터를 입력으로 받아 1차원의 binary classification을 수행할 때](../assets/w2v-decision_boundary.png)
./06-word_embedding/02-dimension-reduction.md	![전형적인 형태의 오토인코더](../assets/w2v-auto-encoder.png)
./06-word_embedding/02-dimension-reduction.md	![병목(bottle-neck) 구간에서의 매니폴드](../assets/w2v-auto-encoder-manifold.png)
./06-word_embedding/02-dimension-reduction.md	![고차원(3차원)에서 저차원(2차원)으로 투사할 때의 정보 손실(복원 오류)](../assets/w2v-manifold-reconstruction-error.png)
./06-word_embedding/02-dimension-reduction.md	![](../assets/w2v-manifold-surface-projection.png)
./06-word_embedding/00-cover.md	![Tomas Mikolov](https://research.fb.com/wp-content/uploads/2016/11/people_tomas-milkolov.jpg){ width=500px }
./09-language_modeling/03-perpexity.md	![주사위 두 개](../assets/lm_rolling_dice.png)
./09-language_modeling/02-n-gram.md	![](../assets/lm-why-smoothing.png)
./09-language_modeling/02-n-gram.md	![](../assets/lm-absolute_discounting.png)
./09-language_modeling/02-n-gram.md	![](../assets/lm_held-out_corpus.png)
./09-language_modeling/06-application.md	![WFST 기반의 전통적인 음성인식 시스템 구조](https://www.esat.kuleuven.be/psi/spraak/demo/Recog/lvr_scheme.gif)
./09-language_modeling/06-application.md	![광학문자인식 시스템의 구성 예시](https://doi.ieeecomputersociety.org/cms/Computer.org/dl/trans/tp/2013/10/figures/ttp20131024131.gif)
./09-language_modeling/05-nnlm.md	![Recurrent Neural 언어모델 구조](../assets/rnn_lm_architecture.png)
./09-language_modeling/00-cover.md	![Daniel Jurafsky](https://c.o0bg.com/rf/image_960w/Boston/2011-2020/2014/10/06/BostonGlobe.com/Lifestyle/Images/Jurafsky,Dan%C2%A9KingmondYoung.jpg){ width=500px }
