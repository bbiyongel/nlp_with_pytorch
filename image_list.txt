Found 102 files.
./14-productization/03-nematus.md	![BPE 알고리즘 - 출처: [[Sennrich at el.2016]](http://www.aclweb.org/anthology/P16-1162)](../assets/14-03-01.png){ width=400px }
./14-productization/04-microsoft.md	![](../assets/14-04-01.png)
./14-productization/04-microsoft.md	![딜리버레이션 네트워크의 개요](../assets/14-04-02.png)
./14-productization/04-microsoft.md	![](../assets/14-04-03.png)
./14-productization/04-microsoft.md	![](../assets/14-04-04.png)
./14-productization/04-microsoft.md	![](../assets/14-04-05.png)
./14-productization/01-pipeline.md	![준비과정 개요도](../assets/14-01-01.png)
./14-productization/02-gnmt.md	![레지듀얼 커넥션을 적용한 모습](../assets/14-02-01.png)
./14-productization/02-gnmt.md	![인코더의 첫번째 레이어에 적용 된 모습](../assets/14-02-02.png)
./14-productization/02-gnmt.md	![](../assets/14-02-03.png)
./14-productization/02-gnmt.md	![양자화에 따른 성능 개선 효과 - 출처: [Wo at el.2016]](../assets/14-02-04.png)
./14-productization/02-gnmt.md	![Optimizer에 따른 손실값의 변화](../assets/14-02-05.png)
./14-productization/02-gnmt.md	![](../assets/14-02-06.png)
./14-productization/00-cover.md	![적절한 번역의 예](../assets/14-00-01.png){ width=500px }
./12-reinforcement_learning/01-intro.md	![GAN의 전형적인 구조](../assets/12-01-01.png)
./12-reinforcement_learning/01-intro.md	![L1 손실함수와 GAN의 생성 결과물 비교 (출처: pix2pix)](../assets/12-01-02.png)
./12-reinforcement_learning/01-intro.md	![GAN을 sequence-to-sequence에 적용하자](../assets/12-01-03.png)
./12-reinforcement_learning/01-intro.md	![샘플링 과정은 그래디언트 전달이 어렵습니다.](../assets/12-01-04.png)
./12-reinforcement_learning/05-supervised-nmt.md	![MRT의 성능 평가](../assets/12-05-01.png)
./12-reinforcement_learning/04-characteristic.md	![강화학습을 기계번역에 적용한다면](../assets/12-04-01.png)
./12-reinforcement_learning/02-rl_basics.md	![강화학습이 동작하는 과정](../assets/12-02-01.png)
./12-reinforcement_learning/02-rl_basics.md	![가위바위보](../assets/12-02-02.png)
./12-reinforcement_learning/02-rl_basics.md	![가장 어려운 고민](../assets/12-02-03.png)
./12-reinforcement_learning/02-rl_basics.md	![백트래킹과 다이나믹 프로그래밍](../assets/12-02-04.png)
./12-reinforcement_learning/02-rl_basics.md	![](../assets/12-02-05.png)
./12-reinforcement_learning/02-rl_basics.md	![뉴럴 네트워크를 활용한 큐 러닝의 개요](../assets/12-02-06.png)
./12-reinforcement_learning/03-policy-gradient.md	![손실 함수를 최소화 하기 위한 그래디언트 디센트 vs 샘플링을 통한 보상의 최대화를 위한 그래디언트 어센트](../assets/12-03-01.png)
./12-reinforcement_learning/03-policy-gradient.md	![폴리시 그래디언트는 샘플링 확률을 최대화 하는 방향으로 그래디언트를 구합니다.](../assets/12-03-02.png)
./12-reinforcement_learning/06-unsupervised-nmt.md	![Unsupervised NMT 개요](../assets/12-06-01.png)
./12-reinforcement_learning/06-unsupervised-nmt.md	![3가지 목적함수가 동작하는 모습](../assets/12-06-02.png)
./12-reinforcement_learning/06-unsupervised-nmt.md	![](../assets/12-06-03.png)
./12-reinforcement_learning/00-cover.md	![Richard S. Sutton 교수](12-00-01.jpeg){ width=500px }
./11-adv_neural_machine_translation/01-multilingual-nmt.md	![Many to One](../assets/11-01-01.png)
./11-adv_neural_machine_translation/01-multilingual-nmt.md	![One to Many](../assets/11-01-02.png)
./11-adv_neural_machine_translation/01-multilingual-nmt.md	![Many to Many](../assets/11-01-03.png)
./11-adv_neural_machine_translation/01-multilingual-nmt.md	![Zero-shot Translation](../assets/11-01-04.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![[[Gulcehre at el.2015]](https://arxiv.org/pdf/1503.03535.pdf)](../assets/11-02-01.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![[[Gulcehre at el.2015]](https://arxiv.org/pdf/1503.03535.pdf)](../assets/11-02-02.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![Back Translation 개요](../assets/11-02-03.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![[[Sennrich at el.2015]](https://arxiv.org/pdf/1511.06709.pdf)](../assets/11-02-04.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![[[Sennrich at el.2017]](https://arxiv.org/pdf/1708.00726.pdf)](../assets/11-02-05.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![](../assets/11-02-06.png)
./11-adv_neural_machine_translation/02-monolingual-corpus.md	![](../assets/11-02-07.png)
./11-adv_neural_machine_translation/03-transformer.md	![트랜스포머의 구조](../assets/11-03-01.png)
./11-adv_neural_machine_translation/03-transformer.md	![포지션 임베딩의 직관적인 설명](../assets/11-03-02.png)
./11-adv_neural_machine_translation/03-transformer.md	![트랜스포머의 어텐션 구성](../assets/11-03-03.png)
./11-adv_neural_machine_translation/03-transformer.md	![트랜스포머는 모든 time-step의 어텐션 연산을 한 번에 수행합니다.](../assets/11-03-04.png)
./11-adv_neural_machine_translation/03-transformer.md	![트랜스포머의 성능 비교](../assets/11-03-05.png)
./11-adv_neural_machine_translation/00-cover.md	![[Christopher Manning](https://nlp.stanford.edu/manning/)](../assets/11-00-01.jpeg){ width=500px }
./08-text_classification/05-cnn.md	![CNN for text classification arthictecture [[Kim at el.2014]](https://arxiv.org/pdf/1408.5882.pdf)](../assets/08-05-01.png)
./08-text_classification/05-cnn.md	![수직, 수평 윤곽선을 검출하기 위한 소벨(Sobel)필터](../assets/08-05-02.gif)
./08-text_classification/05-cnn.md	![소벨 필터 적용 전 (출처: 위키피디아)](../assets/08-05-03.PNG)
./08-text_classification/05-cnn.md	![소벨 필터 적용 후 (출처: 위키피디아)](../assets/08-05-04.PNG)
./08-text_classification/05-cnn.md	![컨볼루션 연산을 적용하는 과정](../assets/08-05-05.png)
./08-text_classification/05-cnn.md	![Example of convolutional neural network for speech recognition [ Abdel-Hamid et al.2014](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/CNN_ASLPTrans2-14.pdf)](../assets/08-05-06.png)
./08-text_classification/05-cnn.md	![두 단어(토큰)의 패턴을 찾는 CNN](../assets/08-05-07.png)
./08-text_classification/05-cnn.md	![cnn_out에서 맥스 풀링을 통해 각 피쳐 별 최고 점수를 뽑아내는 과정](../assets/08-05-08.png)
./08-text_classification/04-rnn.md	![RNN의 마지막 time-step의 출력을 사용 하는 경우](../assets/08-04-01.png)
./08-text_classification/04-rnn.md	![One-hot 벡터로 구성된 정답 샘플과 뉴럴 네트워크를 통해 얻은 discrete 확률 분포 사이의 손실 함수 계산](../assets/08-04-02.png)
./08-text_classification/00-cover.md	![[Thomas Bayes](https://en.wikipedia.org/wiki/Thomas_Bayes) - Image from Wikipedia](../assets/08-00-01.gif)
./04-preprocessing/01-intro.md	![전처리 과정 개요도](../assets/04-01-01.png)
./04-preprocessing/05-align.md	![Jean-François Champollion, 이미지 출처: 위키피디아](../assets/04-05-01.jpg)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/04-03-01.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/04-03-02.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/04-03-03.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/04-03-04.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/04-03-05.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/04-03-06.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/04-03-07.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/04-03-08.png)
./04-preprocessing/03-cleaning-corpus.md	![n번 반복](../assets/04-03-09.png)
./04-preprocessing/03-cleaning-corpus.md	![n번 이상 반복](../assets/04-03-10.png)
./04-preprocessing/03-cleaning-corpus.md	![n번에서 m번 사이 반복](../assets/04-03-11.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/04-03-12.png)
./04-preprocessing/03-cleaning-corpus.md	![](../assets/04-03-13.png)
./04-preprocessing/03-cleaning-corpus.md	![이미지 출처: [regexper.com](https://regexper.com/)](../assets/04-03-14.png)
./04-preprocessing/03-cleaning-corpus.md	![치환자 사용의 예](../assets/04-03-15.png)
./04-preprocessing/00-cover.md	![Noam Chomsky](../assets/04-00-01.jpg){ width=400px }
./02-basic_math/02-prob-dist.md	![주사위의 확률 질량 함수(probability mass function)](../assets/02-02-01.png)
./02-basic_math/02-prob-dist.md	![가우시안 분포의 확률 밀도 함수(probability density funcion)](../assets/02-02-02.png)
./02-basic_math/02-prob-dist.md	![Marginal 확률 분포의 개념](../assets/02-02-03.png)
./02-basic_math/05-mle.md	![어느 평범한 압정](../assets/02-05-01.png)
./02-basic_math/05-mle.md	![Likelihood 함수 곡선](../assets/02-05-02.png)
./02-basic_math/05-mle.md	![뉴럴 네트워크는 확률분포 함수 입니다.](../assets/02-05-03.png)
./02-basic_math/06-information.md	![flat한 분포와 sharp한 분포](../assets/02-06-01.png)
./02-basic_math/06-information.md	![크로스 엔트로피의 직관적인 표현](../assets/02-06-02.png)
./02-basic_math/04-sampling.md	![주사위](../assets/02-04-01.png)
./02-basic_math/04-sampling.md	![한반도의 넓이를 근사하고 싶다면?](../assets/02-04-02.png)
./02-basic_math/03-monty-hall.md	![몬티홀 문제](../assets/02-03-01.png)
./02-basic_math/00-cover.md	![Claude Elwood Shannon - 이미지 출처: 위키피디아](../assets/02-00-01.jpg){ width=500px }
./05-word_senses/01-intro.md	![단어의 형태들과 내부 의미들이 갖는 관계](../assets/05-01-01.png)
./05-word_senses/07-similarity.md	![L1 vs L2(초록색) from wikipedia](../assets/05-07-01.png)
./05-word_senses/07-similarity.md	![같은 값 $r$ 크기를 갖는 $L_1$ , $L_2$ , $L_\infty$ 거리를 그림으로 나타낸 모습](../assets/05-07-02.png)
./05-word_senses/04-feature.md	![각 피쳐에 따른 MNIST 예제](../assets/05-04-01.png)
./05-word_senses/09-selectional-preference.md	![클래스의 사전 확률 분포와 술어가 주어졌을 때의 확률 분포 변화](../assets/05-09-01.png)
./05-word_senses/09-selectional-preference.md	![](../assets/05-09-02.png)
./05-word_senses/02-one-hot-encoding.md	![Discrete 확률 분포로부터 샘플링하여 얻어지는 One-hot 벡터](../assets/05-02-01.png)
./05-word_senses/02-one-hot-encoding.md	![차원의 저주: 차원이 높을 수록 같은 정보를 표현하는데 불리합니다.](../assets/05-02-02.png)
./05-word_senses/03-wordnet.md	![각 단어별 top-1 의미의 top-1 상위어만 선택하여 트리 구조로 나타낸 경우](../assets/05-03-01.png)
./05-word_senses/03-wordnet.md	![[워드넷 웹사이트](http://wordnetweb.princeton.edu/perl/webwn)에서 단어 'bank'를 검색 한 결과](../assets/05-03-02.png)
./05-word_senses/03-wordnet.md	![각 단어들의 쿼리 결과 구조도](../assets/05-03-03.png)
./05-word_senses/03-wordnet.md	!['student'와 'fireman' 사이에 위치한 노드들(점선)](../assets/05-03-04.png)
./05-word_senses/06-vectorization.md	![컨텍스트 윈도우를 수행한 결과](../assets/05-06-01.png)
./05-word_senses/06-vectorization.md	![대부분의 값이 0으로 채워진 sparse 벡터](../assets/05-06-02.png)
./05-word_senses/06-vectorization.md	![피쳐 벡터들을 tSNE로 표현한 모습](../assets/05-06-03.png)
./05-word_senses/00-cover.md	![Philip Resnik](../assets/05-00-01.jpg){ width=500px }
./07-sequential_modeling/03-lstm.md	![LSTM의 구조](../assets/07-03-01.png)
./07-sequential_modeling/05-gradient-clipping.md	![그래디언트의 방향은 유지한 채, 크기만 달라지는 모습](../assets/07-05-01.png)
./07-sequential_modeling/02-rnn.md	![기존 뉴럴 네트워크 구조](../assets/07-02-01.png)
./07-sequential_modeling/02-rnn.md	![Recursive한 속성이 부여된 뉴럴넷 구조](../assets/07-02-02.png)
./07-sequential_modeling/02-rnn.md	![기본적인 RNN의 피드포워드 형태](../assets/07-02-03.png)
./07-sequential_modeling/02-rnn.md	![RNN의 입력 텐서 (n time-step)](../assets/07-02-04.png)
./07-sequential_modeling/02-rnn.md	![여러 time-step의 히든스테이트들을 이어붙여 전체 time-step에 대한 히든스테이트로 만드는 모습](../assets/07-02-05.png)
./07-sequential_modeling/02-rnn.md	![RNN에서 BPTT가 되는 모습](../assets/07-02-06.png)
./07-sequential_modeling/02-rnn.md	![빨간색: tanh, 파란색: sigmoid](../assets/07-02-07.png)
./07-sequential_modeling/02-rnn.md	![빨간색: tanh의 도함수, 파란색: sigmoid의 도함수](../assets/07-02-08.png)
./07-sequential_modeling/02-rnn.md	![여러 층이 쌓인 RNN의 형태](../assets/07-02-09.png)
./07-sequential_modeling/02-rnn.md	![RNN의 출력 텐서 (n time-step)](../assets/07-02-10.png)
./07-sequential_modeling/02-rnn.md	![여러개의 레이어를 가진 RNN의 히든스테이트 (1 time-step)](../assets/07-02-11.png)
./07-sequential_modeling/02-rnn.md	![두 방향으로 히든 스테이트를 전달 및 계산하는 RNN의 형태](../assets/07-02-12.png)
./07-sequential_modeling/02-rnn.md	![여러개의 레이어를 가진 양방향 RNN의 히든스테이트 (1 time-step)](../assets/07-02-13.png)
./07-sequential_modeling/02-rnn.md	![각 타입 별 RNN의 형태](../assets/07-02-14.png)
./07-sequential_modeling/02-rnn.md	![RNN의 마지막 time-step의 출력을 사용 하는 경우](../assets/07-02-15.png)
./07-sequential_modeling/02-rnn.md	![모든 time-step의 출력을 사용 하는 경우](../assets/07-02-16.png)
./07-sequential_modeling/04-gru.md	![GRU의 구조](../assets/07-04-01.png)
./07-sequential_modeling/00-cover.md	![Andrey Markov](../assets/07-00-01.jpg){ width=500px }
./01-introduction/01-intro.md	![텍스트는 사람과 컴퓨터 사이의 가장 훌륭한 인터페이스 입니다.](../assets/01-01-01.png)
./01-introduction/04-korean-is-hell.md	![내동생 고기 vs 내동 생고기](../assets/01-04-01.png)
./01-introduction/04-korean-is-hell.md	![농협용 인육 가공 vs 농협 용인 육가공](../assets/01-04-02.png)
./01-introduction/02-deeplearning.md	![이미지넷의 최근 성능 변화](../assets/01-02-01.png)
./01-introduction/02-deeplearning.md	![전통적인 음성인식 시스템의 구성](../assets/01-02-02.gif)
./01-introduction/02-deeplearning.md	![음성인식의 정확도](../assets/01-02-03.png)
./01-introduction/02-deeplearning.md	![2014년까지 참 안타까웠습니다.](../assets/01-02-04.png)
./01-introduction/02-deeplearning.md	![통계기반 기게번역 시스템을 구성하는 서브 모듈 (SMT)](../assets/01-02-05.jpg)
./01-introduction/02-deeplearning.md	![기계번역의 역사](../assets/01-02-06.png)
./01-introduction/02-deeplearning.md	![2014년부터 2018년까지 GAN의 역사를 한장에](../assets/01-02-07.png)
./01-introduction/02-deeplearning.md	![[[Gao et al.2017](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/dl-summer-school-2017.-Jianfeng-Gao.v2.pdf)]](../assets/01-02-08.png)
./01-introduction/02-deeplearning.md	![[[Gao et al.2017](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/dl-summer-school-2017.-Jianfeng-Gao.v2.pdf)]](../assets/01-02-09.png)
./01-introduction/02-deeplearning.md	![[[Gao et al.2017](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/dl-summer-school-2017.-Jianfeng-Gao.v2.pdf)]](../assets/01-02-10.png)
./01-introduction/02-deeplearning.md	![[[Gao et al.2017](https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/dl-summer-school-2017.-Jianfeng-Gao.v2.pdf)]](../assets/01-02-11.png)
./01-introduction/02-deeplearning.md	![아카이브에 출판된 딥러닝 관련 논문 수 - 출처: [Karpathy's medium](https://medium.com/@karpathy/a-peek-at-trends-in-machine-learning-ab8a1085a106)](../assets/01-02-12.png)
./01-introduction/05-trends.md	![[Mikolov et al.2010]](../assets/01-05-01.png)
./01-introduction/05-trends.md	![Skip-gram과 CBOW의 구조 [Mikolov et al.2013]](../assets/01-05-02.png)
./01-introduction/05-trends.md	![Word Vector Visualization](../assets/01-05-03.png)
./01-introduction/05-trends.md	![CNN 텍스트 분로 모델 [Kim et al.2014]](../assets/01-05-04.png)
./01-introduction/05-trends.md	![어텐션을 통해 두 문장 사이의 단어간 정렬이 된 모습](../assets/01-05-05.png)
./01-introduction/05-trends.md	![[Graves et al.2016]](../assets/01-05-06.png)
./01-introduction/05-trends.md	![[[Yu et al.2016]](https://arxiv.org/abs/1609.05473)](../assets/01-05-07.png)
./01-introduction/00-cover.md	![TARS from Interstellar - Image from [web](https://www.wired.com/2014/11/interstellar-droids/)](../assets/01-00-01.jpg){ width=500px }
./10-neural_machine_translation/06-beam-search.md	![샘플링 또는 그리디 탐색을 통한 추론 과정](../assets/10-06-01.png)
./10-neural_machine_translation/06-beam-search.md	![하나의 문장을 번역 할 때, 빔 사이즈 k=3인 경우의 빔서치](../assets/10-06-02.png)
./10-neural_machine_translation/06-beam-search.md	![](../assets/10-06-03.png)
./10-neural_machine_translation/06-beam-search.md	![각 추론 방법에 따른 성능 비교 - 출처: [Cho et al.2016]](../assets/10-06-04.png)
./10-neural_machine_translation/06-beam-search.md	![빔 사이즈 k=3인 경우의 병렬 빔서치 수행](../assets/10-06-05.png)
./10-neural_machine_translation/06-beam-search.md	![미니배치 내에서 빔서치를 병렬로 수행하기 위한 과정](../assets/10-06-06.png)
./10-neural_machine_translation/01-intro.md	![대표적인 번역 실패 사례](../assets/10-01-01.png)
./10-neural_machine_translation/01-intro.md	![[오토인코더 기반의 신경망 기계번역](http://web.stanford.edu/class/cs224n/syllabus.html)](../assets/10-01-02.png)
./10-neural_machine_translation/01-intro.md	![[통계기반 기계번역 vs 신경망 기계번역](http://web.stanford.edu/class/cs224n/syllabus.html)](../assets/10-01-03.png)
./10-neural_machine_translation/05-teacher-forcing.md	![훈련방식과 추론방식](../assets/10-05-01.png)
./10-neural_machine_translation/02-seq2seq.md	![3개의 구성요소로 이루어진 기본적인 Sequence-to-Sequence 구조](../assets/10-02-01.png)
./10-neural_machine_translation/02-seq2seq.md	![인코더의 문장 임베딩](../assets/10-02-02.png)
./10-neural_machine_translation/03-attention.md	![어텐션이 추가된 Sequence-to-Sequence의 구조](../assets/10-03-01.png)
./10-neural_machine_translation/03-attention.md	![인코더의 출력값과 디코더의 출력값 사이의 선형 맵핑](../assets/10-03-02.png)
./10-neural_machine_translation/03-attention.md	![어텐션이 번역에서 동작하는 직관적인 예](../assets/10-03-03.png)
./10-neural_machine_translation/03-attention.md	![[어텐션의 사용여부에 따른 문장 길이별 번역 성능](http://web.stanford.edu/class/cs224n/syllabus.html)](../assets/10-03-04.png)
./10-neural_machine_translation/03-attention.md	![파이토치 배치 행렬곱 연산](../assets/10-03-05.png)
./10-neural_machine_translation/04-input-feeding.md	![Input Feeding이 추가 된 Sequence-to-Sequence 구조](../assets/10-04-01.png)
./10-neural_machine_translation/04-input-feeding.md	![문장 길이에 따른 미니배치의 형태](../assets/10-04-02.png)
./10-neural_machine_translation/04-input-feeding.md	![마스크가 적용되었을 때 어텐션](../assets/10-04-03.png)
./10-neural_machine_translation/04-input-feeding.md	![Bi-directional LSTM의 히든 스테이트를 uni-directional LSTM의 히든 스테이트로 바꾸기](../assets/10-04-04.png)
./10-neural_machine_translation/00-cover.md	![[Kyunghyun Cho](http://www.kyunghyuncho.me/)](../assets/10-00-01.jpg)
./13-duality/01-intro.md	![듀얼리티의 예](../assets/13-01-01.png)
./13-duality/01-intro.md	![CycleGAN이 성공적으로 적용된 예제](../assets/13-01-02.jpg)
./13-duality/01-intro.md	![CycleGAN의 동작 개요](../assets/13-01-03.png)
./13-duality/04-back_translation.md	![젠슨스 부등식의 예](../assets/13-04-01.png)
./13-duality/02-dsl.md	![](../assets/13-02-01.png)
./13-duality/03-dul.md	![기계번역 듀얼러닝의 알고리즘](../assets/13-03-01.png)
./13-duality/03-dul.md	![](../assets/13-03-02.png)
./13-duality/03-dul.md	![듀얼러닝의 적용 결과](../assets/13-03-03.png)
./13-duality/03-dul.md	![](../assets/13-03-04.png)
./13-duality/00-cover.md	![[Dr. Rico Sennrich](http://homepages.inf.ed.ac.uk/rsennric/)](../assets/13-00-01.jpg){ width=400px }
./03-pytorch_tutorial/02-how-to-install.md	![파이토치 홈페이지에서는 그림에서와 같이 사용자의 설정에 따른 설치 명령을 제공 합니다.](../assets/03-02-01.png)
./03-pytorch_tutorial/02-how-to-install.md	![PyTorch 로고](../assets/03-02-02.png)
./03-pytorch_tutorial/02-how-to-install.md	![시간별 딥러닝 프레임워크의 점유율 변화 출처: [Karpathy's medium](https://medium.com/@karpathy/a-peek-at-trends-in-machine-learning-ab8a1085a106)](../assets/03-02-03.png)
./03-pytorch_tutorial/02-how-to-install.md	![[Image from [Karpathy's twitter](https://twitter.com/karpathy/status/868178954032513024)](../assets/03-02-04.png)
./03-pytorch_tutorial/03-hello-pytorch.md	![연산에 의해 생성된 그래프의 예](../assets/03-03-01.png)
./03-pytorch_tutorial/00-cover.md	![Geoffrey Hinton](../assets/03-00-01.jpg){ width=500px }
./06-word_embedding/03-myth.md	![임베딩 레이어의 동작 개념](../assets/06-03-01.png)
./06-word_embedding/04-word2vec.md	![CBOW와 Skip-gram 알고리즘](../assets/06-04-01.png)
./06-word_embedding/04-word2vec.md	![Skip-gram의 아키텍쳐](../assets/06-04-02.png)
./06-word_embedding/04-word2vec.md	![Skip-gram을 통해 얻은 word embedding 벡터를 t-SNE를 통해 visualization 한 예제](../assets/06-04-03.png)
./06-word_embedding/06-example.md	![텐서보드를 통한 시각화 예제](../assets/06-06-01.png)
./06-word_embedding/06-example.md	![텐서보드를 통한 시각화 예제](../assets/06-06-02.gif)
./06-word_embedding/02-dimension-reduction.md	![심지어 One-hot 벡터의 경우에는 아래와 같이 차원 축소가 가능할 것 입니다.](../assets/06-02-01.png)
./06-word_embedding/02-dimension-reduction.md	![3차원에서 2차원, 다시 1차원으로 PCA를 수행하는 예](../assets/06-02-02.png)
./06-word_embedding/02-dimension-reduction.md	![주성분의 조건](../assets/06-02-03.png)
./06-word_embedding/02-dimension-reduction.md	![3차원 공간 상에 기묘한 모양으로 분포한 샘플들이 2차원 매니폴드에 속하는 모습](../assets/06-02-04.png)
./06-word_embedding/02-dimension-reduction.md	![3차원 공간상의 2차원 매니폴드를 2차원 공간에서 표현하였을 때, 각 점 사이의 최단경로](../assets/06-02-05.png)
./06-word_embedding/02-dimension-reduction.md	![MNIST 데이터를 2차원 매니폴드에 표현하였을 때, 두 샘플의 위치](../assets/06-02-06.png)
./06-word_embedding/02-dimension-reduction.md	![3차원 데이터를 입력으로 받아 1차원의 binary classification을 수행할 때](../assets/06-02-07.png)
./06-word_embedding/02-dimension-reduction.md	![전형적인 형태의 오토인코더](../assets/06-02-08.png)
./06-word_embedding/02-dimension-reduction.md	![병목(bottle-neck) 구간에서의 매니폴드](../assets/06-02-09.png)
./06-word_embedding/02-dimension-reduction.md	![고차원(3차원)에서 저차원(2차원)으로 투사할 때의 정보 손실(복원 오류)](../assets/06-02-10.png)
./06-word_embedding/02-dimension-reduction.md	![](../assets/06-02-11.png)
./06-word_embedding/00-cover.md	![Tomas Mikolov](../assets/06-00-01.jpg){ width=500px }
./09-language_modeling/03-perpexity.md	![주사위 두 개](../assets/09-03-01.png)
./09-language_modeling/02-n-gram.md	![](../assets/09-02-01.png)
./09-language_modeling/02-n-gram.md	![](../assets/09-02-02.png)
./09-language_modeling/02-n-gram.md	![](../assets/09-02-03.png)
./09-language_modeling/06-application.md	![WFST 기반의 전통적인 음성인식 시스템 구조](../assets/09-06-01.gif)
./09-language_modeling/06-application.md	![광학문자인식 시스템의 구성 예시](../assets/09-06-02.gif)
./09-language_modeling/05-nnlm.md	![Recurrent Neural 언어모델 구조](../assets/09-05-01.png)
./09-language_modeling/00-cover.md	![Daniel Jurafsky](../assets/09-00-01.jpg){ width=500px }
