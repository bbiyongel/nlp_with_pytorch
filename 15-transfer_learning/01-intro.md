# 전이학습이란

전이학습(transfer learning)이란 신경망의 일부 또는 전체 웨이트 파라미터를 MLE를 통해 학습 데이터에 본격적으로 훈련 시키기에 앞서, 다른 데이터셋이나 목적함수(objective function)을 사용하여 미리 훈련한 후에, 이를 바탕으로 본격적인 학습에서 신경망 웨이트 파라미터에 대한 최적화를 좀 더 쉽게 할 수 있게 되는 것을 이릅니다.  이미 영상처리(computer vision)분야에서는 수년전부터 이미지넷(ImageNet)에서 사용되던 신경망 웨이트 파라미터값을 사용하여 다른 문제에 전이학습을 적용하는 것이 흔한 접근 방법이었습니다. 그동안 자연어 처리 분야에서는 전이학습을 사용하기 보단 본질적인 문제 해결에 집중 해 온 모양새였습니다. 하지만, 최근 많은 문제들이 딥러닝을 통해 어느정도 해결이 되면서, 성능을 극대화 시킬 수 있는 방법들을 모색하기 시작하였고, 여러가지 기존의 문제점들을 보완한 전이학습 방법이 제시되고 각종 자연어 처리 문제 해결에서 뛰어난 성능을 보이면서 점점 주류로 자리잡아 가는 추세 입니다.

사전에 훈련된 신경망의 각 계층들은 문제를 해결하기 위한 데이터들을 잘 설명할 수 있는 특징(feature)들을 추출하도록 훈련되어 있을 것 입니다. 따라서 만약 우리가 비슷한 특징을 지닌 데이터셋을 가지고 유사한 문제를 해결하고자 한다면, 랜덤하게 초기화 되어 있는 상태의 웨이트 파라미터에서 최적화를 시작하는 것보다, 기존에 이미 훈련되어 있는 웨이트 파라미터에서 조금만 바꿔서 새로운 문제를 풀도록 한다면 훨씬 더 쉬울 수 있습니다. 즉, 랜덤 초기값에서 최적화를 시작하는 것은 데이터셋의 노이즈(noise)와 경사하강법(gradient descent)의 한계 때문에 어려움이 있을 수 있지만, 사전훈련된 웨이트 파라미터 값에서 최적화를 시작하는 것은 앞선 문제를 어느정도 해결해 줄 수도 있습니다. 따라서, 사전훈련을 통해 우리는 좀더 높은 성능을 기대할 수 있을 것 입니다. 물론 당연히 완전 다른 성격의 데이터셋 또는 다른 성격의 문제를 해결할 때에 사전훈련은 그만큼 도움이 되지 않을 가능성이 높습니다.

게다가, 만약 사전훈련에 사용되었던 훈련 데이터셋이 매우 방대하고 자세한 정보를 담고 있었다면, 미처 새로운 문제를 위한 데이터셋이 담고 있지 않은 정보를 포함하고 있었을 수도 있습니다. 그렇다면, 랜덤 초기값에서부터 훈련시킬 때에는 얻을 수 없었던 해결 능력을 덤으로 얻을 수도 있을 것이고, 사전훈련 덕분에 성능이 향상 될 것 입니다.
