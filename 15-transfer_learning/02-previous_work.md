# 기존의 사전훈련 방식

Word2Vec이 등장한 이후, 사람들은 꾸준히 사전훈련된(pretrained) 단어 임베딩 벡터(word embedding vector)를 사용하여 딥러닝 모델을 개선하려 하였습니다. 앞서 단어 임베딩 벡터와 관련된 내용을 다룬 장에서는, 이와 관련하여 사람들이 흔히 갖고 있는 잘못된 개념이라고 설명하였습니다. 물론 기훈련된 단어 임베딩 벡터들을 기존의 머신러닝 알고리즘에 적용하였을 때는 성과가 있을 수 있지만, 딥러닝 모델에서는 생각보다 큰 효과를 거둘 수 없었기 때문입니다. 사전훈련된 단어 임베딩 벡터를 사용하여 텍스트 분류와 같은 문제에 적용할 때, 사용할 수 있는 방법은 아래와 같습니다.

## 사전훈련된 웨이트 파라미터를 사용하는 방법

### 신경망 웨이트 파라미터 초기값으로 사용

### 신경망 웨이트 파라미터 값으로 고정

### 신경망 웨이트 파라미터 초기값으로 사용 및 느린 학습

## 사전훈련된 워드 임베딩 벡터를 사용하는 것이 성공하지 못하는 이유

### 기존의 단어 임베딩 알고리즘은 문장의 문맥을 반영하지 못함

### 신경망의 입력 계층의 웨이트 파라미터에만 적용됨

## 자연어 처리에서 전이학습의 효과

이번 장에서 소개할 자연어 처리에 전이학습을 적용하기 위한 방법들은 위에서 열거한 기존의 단점들을 효과적으로 보완한 것이 특징입니다. 따라서, 기존의 자연어 처리 문제에 다양하게 적용되어 성공을 거둘 수 있었습니다. 이에 따라, 마치 영상처리(computer vision) 분야에서 성공한 이미지넷의 사전훈련된 신경망 웨이트 파라미터들을 여러 다른 영상처리 분야에 활발하게 사용하였던 것 처럼, 자연어 처리 분야에서도 수많은 문장들을 수집하여 학습한 신경망을 통해 다른 문제에 성공적으로 적용 및 성능을 개선 할 수 있는 방법이 마련되었습니다.