# 정리

이번 챕터에서는 단어 임베딩 방법에 대해서 이야기 하였습니다. 이전 챕터에서는 피쳐 백터를 TF-IDF 방식으로 구성하여 사용하였지만 여전히 굉장히 희소(sparse)하였고, 단어를 대표하는 값으로 사용하기에는 여전히 문제가 있었습니다. 따라서 이번 챕터에서는 차원 축소에 대해서 이야기 하였고, 선형(linear) 차원축소 알고리즘에 비해서 뉴럴 네트워크를 통해 비선형(non-linear)적인 데이터 분포를 효과적으로 차원축소하는 것이 바로 뉴럴 네트워크가 잘 동작하는 이유라고 이야기 하였습니다.

Word2Vec은 하지만 비선형적인 방법을 사용하지 않고도 매우 좋은 단어 임베딩을 구현하였으며, 자연어처리 분야에 새 지평을 열었습니다. 또한 GloVe는 더 나아가 좀 더 빠르고 정확한 단어 임베딩 방법을 제시하였습니다. 우리는 이러한 방법들을 사용하여 이제 단어 사이의 유사도를 데이터에 기반하여 효과적으로 정확하게 계산할 수 있게 되었습니다. 하지만 앞으로 소개될 텍스트 분류나 자연어 생성과 같은 기법들에는 이 챕터에서 소개한 단어 임베딩 알고리즘이 사용되지 않고, 단순히 임베딩 레이어를 사용하는것이 더 정확하고 효율적인 방법임을 이야기 하였습니다. 앞으로 소개할 챕터들에서는 본격적으로 문장 단위의 자연어처리를 하는 방법들을 소개 하고자 합니다.
