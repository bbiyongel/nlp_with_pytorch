# 기계번역 (Machine Translation, MT)

번역은 인류가 언어를 사용하기 시작한 이래로 큰 관심사 중에 하나였습니다. 그러한 의미에서 기계 번역(Machine Translation)은 단순히 언어를 번역하는 것이 아닌, 자연언어처리 영역에서의 종합예술이라 할 수 있습니다. 사실 이번 챕터를 위해서 이전 챕터들을 다루었다고 해도 과언이 아닙니다. 신경망번역(Neural Machine Translation, NMT)은 end-to-end 학습으로써, 규칙기반 기계번역(Rule Based Machine Translation, RBMT), 통계기반 기계번역(Statistical Machine Translation, SMT)으로로 이어져온 기계 번역의 수십년 역사 중에서 가장 큰 성취를 이루어냈습니다. 이번 챕터는 NMT에 대한 방법과 인사이트를 얻을 수 있도록, sequence-to-sequence와 attention의 동작 방식과 원리를 이해하고, 더 나아가 응용 방법에 대해서도 소개 합니다. 또한, 기계번역 시스템을 만들기 위한 프로세스와 최신 연구 동향을 아울러 소개 합니다.

## 번역의 목표

$$\hat{e} = \text{argmax }P_{f \rightarrow e}(e|f)$$

번역의 궁극적인 목표는 어떤 언어 $f$ 의 문장이 주어졌을 때, 우리가 원하는 언어 $e$ 로 확률을 최대로 하는 문장 $\hat{e}$ 을 찾아내는 것 입니다.

### 왜 번역은 어려울까

인간의 언어는 컴퓨터의 언어(프로그래밍 언어)와 같이 명확하지 않습니다. 우리는 언어의 모호성(ambiguity)을 적극적으로 활용함으로써, 의사소통의 효율을 극대화 합니다. 예를 들어 우리는 정보나 단어를 생략하고 문장을 짧게 만든다거나, 같은 단어와 어절이라고 하더라도 때에 따라 다른 의미로 해석될 수 있습니다. 더욱이 한국어의 경우에는 앞 챕터에서 다루었듯이 어순이 불규칙하고 주어가 생략 되는 등, 다른 언어에 비해 더욱 그 효율이 극대화 되었습니다. 또한, 언어라는 것은 그 민족의 문화를 담고 있기 때문에, 수 천년의 세월동안 쌓여온 사람들의 의식, 철학이 담겨져있고, 그러한 문화의 차이들로 하여금 번역을 더욱 어렵게 만듭니다. 결국, 이러한 특징들은 기계가 우리의 말을 번역하고자 할 때 큰 장벽으로 다가옵니다.

![대표적인 번역 실패 사례](../assets/nmt-no-evil.png)

|원문|오번역|
|-|-|
|In brightest day, in blackest night,|일기가 좋은 날, 진흙같은 어두운 밤,|
|No evil shall escape my sight.|아니다 이 악마야, 내 앞에서 사라지지.|
|Let those who worship evil's might,|누가 사악한 수도악마를 숭배하는지 볼까,|
|Beware my power, Green Lantern's light!!!|나의 능력을 조심해라, 그린 랜턴 빛!|

### 왜 번역 기술은 중요할까

하지만 이러한 어려움에도 불구하고 기계 번역은 우리에게 꼭 필요한 과제입니다. 이 순간에도 전세계에서는 기계번역을 통해서 많은 일들이 일어납니다. 페이스북과 같은 세계인이 소통하는 소셜네트워크, [아마존](https://arxiv.org/pdf/1712.05690.pdf)과 같은 전 세계를 대상으로 하는 인터넷 쇼핑몰에서도 번역 서비스를 제공하며 사용자들은 이를 통해 편리함을 얻을 수 있습니다.

## 기계번역의 역사

### 규칙기반 기계번역 (Rule based Machine Translation)

규칙 기반의 기계번역은 우리가 흔히 어릴때 부터 배워 온 방식으로 가장 전통적인 방식의 번역 입니다. 주어진 문장의 구조를 분석하고, 그 분석에 따라 규칙을 세우고 분류를 나누어서 정해진 규칙에 따라서 번역을 합니다. 사람의 경우에는 일반화(generalization) 능력이 뛰어나기 때문에 몇 가지 규칙으로도 훌륭하게 적용하여 번역을 수행할 수 있지만, 컴퓨터의 경우에는 사람에 비해 일반화 능력이 현저히 떨어지기 때문에 규칙 기반 기계번역은 매우 어렵습니다. 잘 만들어진 규칙 아래에서는 밑에서 다룰 통계기반 기계번역에 비해서 자연스러운 표현이 가능하지만, 그 규칙을 일일히 사람이 만들어내야 하므로 번역기를 만드는데 많은 자원과 시간이 소모됩니다. 따라서 번역 언어쌍을 확장할 때에도, 매번 새로운 규칙을 찾아내고 적용해야 하기 때문에 굉장히 불리합니다.

### 통계기반 기계번역 (Statistical Machine Translation)

신경망 기계번역(NMT) 이전에 세상을 지배하던 번역 방식입니다. 대량의 양방향 코퍼스로부터 통계를 얻어내어 번역 시스템을 구성합니다. 구글이이 자신의 번역 시스템에 도입하면서 더욱 유명해졌습니다. 이 시스템 또한 여러가지 모듈로 이루어져 굉장히 복잡합니다. 통계기반 방식을 사용하므로 언어쌍을 확장할 때, 대부분의 알고리즘이나 시스템은 유지되므로 기존의 규칙기반 기계번역(RBMT)에 비하여 매우 유리하였습니다.

### 신경망 기계번역 (Neural Machine Translation)

![[오토인코더 기반의 신경망 기계번역](http://web.stanford.edu/class/cs224n/syllabus.html)](../assets/nmt-autoencoder.png)

사실, 딥러닝 이전의 인공지능의 전성기(1980년대)에도 신경망을 사용하여 기계번역 문제를 해결하려는 시도는 여럿 있었습니다. 당시에도 $\text{Encoder} \longrightarrow \text{Decoder}$ 형태의 구조를 가지고 있었지만, 당연히 지금과 같은 성능을 내기는 어려웠습니다.

### 딥러닝의 정복

![[통계기반 기계번역 vs 신경망 기계번역](http://web.stanford.edu/class/cs224n/syllabus.html)](../assets/nmt-progress-in-mt.png)

현재의 딥러닝을 활용한 방식이 제안되고, 곧 기존의 통계기반 기계번역 방식을 크게 앞질러 버렸습니다. 이제는 구글의 번역기 뿐만 아니라, 특별한 경우를 제외하고 거의 모든 상용 번역기는 딥러닝 기반의 번역기술로 대체 되었습니다. 왜 이렇게 신경망 기계번역은 잘 동작하는 것일까요? 앞으로 신경망 기반의 기계번역기술에 대해서 살펴보겠지만, 신경망 기계번역의 장점을 정리하면 아래와 같습니다.

|번호|항목|내용|
|-|-|-|
|1|End-to-end 모델|신경망 기계번역 이전의 통계기반 기계번역의 경우에는 번역시스템이 여러가지 모듈로 구성이 되어 있었고, 이로 하여금 시스템의 복잡도를 증가시켜 훈련에 있어서 훨씬 지금보다 어려운 경향이 있었습니다. 하지만 딥러닝을 활용한 신경망 기계번역 방식은 단 하나의 모델로 번역을 해결함으로써, 성능을 극대화 하였습니다.|
|2|더 나은 언어모델|신경망 언어모델(Neural Network Language Model)을 기반으로 하는 구조이므로 기존의 통계기반 기계번역 방식에 속해있던 n-gram 방식의 언어모델보다 더 강합니다. 따라서 희소성(sparseness)문제가 해결 되었으며, 자연스러운 번역 결과 문장을 생성함에 있어서 더 강점을 나타냅니다.|
|3|훌륭한 문장 임베딩|뉴럴 네트워크의 특기를 발휘하여 문장을 차원축소하여 임베딩 벡터(embedding vector)로 만들어내는 능력이 탁월합니다. 따라서 단어 단위보다 문장 단위에서 문제가 더 심각하게 발생할 수 있는 노이즈나 희소성(sparseness) 문제에도 훨씬 더 잘 대처할 수 있게 되었습니다.|
